import logging
from flask import Flask, render_template, request, jsonify, Response
import google.generativeai as genai
import os
from dotenv import load_dotenv
import traceback
import json
from analysis_stages import STAGES_DETAILS, get_stage_prompt
import time

# Configure logging with colors
class ColoredFormatter(logging.Formatter):
    """Custom formatter with colors"""
    grey = "\x1b[38;21m"
    blue = "\x1b[38;5;39m"
    yellow = "\x1b[38;5;226m"
    red = "\x1b[38;5;196m"
    bold_red = "\x1b[31;1m"
    reset = "\x1b[0m"

    def __init__(self, fmt):
        super().__init__()
        self.fmt = fmt
        self.FORMATS = {
            logging.DEBUG: self.grey + self.fmt + self.reset,
            logging.INFO: self.blue + self.fmt + self.reset,
            logging.WARNING: self.yellow + self.fmt + self.reset,
            logging.ERROR: self.red + self.fmt + self.reset,
            logging.CRITICAL: self.bold_red + self.fmt + self.reset
        }

    def format(self, record):
        log_fmt = self.FORMATS.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)

# Configure logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
fmt = ColoredFormatter('%(asctime)s - %(levelname)s - %(message)s')
ch.setFormatter(fmt)
logger.addHandler(ch)

# Load environment variables
load_dotenv()

# Get API key
GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GEMINI_API_KEY:
    logger.error("API key not found in .env file")
    raise ValueError("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ¹ÙŠÙŠÙ† GOOGLE_API_KEY ÙÙŠ Ù…Ù„Ù .env")

logger.info(f"API Key found: {GEMINI_API_KEY[:5]}...{GEMINI_API_KEY[-5:]}")

# Configure Gemini API
genai.configure(api_key=GEMINI_API_KEY)

# Initialize Flask app
app = Flask(__name__)

# Define the 12 stages in order
STAGES = [
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø·Ø¨Ù‚Ø©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø®Ø§Ù…Ø³Ø©: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø³Ø§Ø¯Ø³Ø©: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ‚Ù‡ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¸Ø±ÙˆÙ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù…Ù†Ø©: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù…ÙƒÙ†Ø©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ø³Ø¹Ø©: ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¹Ø§Ø´Ø±Ø©: Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ù…Ø«Ù„",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±Ø©: ØµÙŠØ§ØºØ© Ø§Ù„Ø­Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ",
    "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±Ø©: ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ØªÙˆØµÙŠØ§Øª"
]

def verify_and_enhance_analysis(model, stage, analysis, text):
    """Verify and enhance the analysis for accuracy and completeness"""
    try:
        logger.info(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© ØªØ­Ù„ÙŠÙ„ {stage}")
        
        # Create verification prompt
        verification_prompt = f"""
        Ù‚Ù… Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„Ù…Ø±Ø­Ù„Ø©: {stage}
        
        Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:
        {text}
        
        Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ:
        {analysis}
        
        Ù‚Ù… Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:
        1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        2. ØªØ£ÙƒØ¯ Ù…Ù† ØªØºØ·ÙŠØ© Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù…Ø±Ø­Ù„Ø©
        3. Ø£Ø¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù‡Ù…Ø© Ù…ÙÙ‚ÙˆØ¯Ø©
        4. ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
        5. Ù‚Ù… Ø¨ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙŠØ§ØºØ© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­
        
        Ù‚Ø¯Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ø´Ø±Ø­ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ…Øª.
        """
        
        # Get enhanced analysis
        response = model.generate_content(verification_prompt)
        if response and response.text:
            enhanced_analysis = response.text
            logger.info(f"âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ {stage}")
            return enhanced_analysis
        else:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø³Ù† Ù„Ù€ {stage}")
            return analysis
            
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù„ÙŠÙ„ {stage}: {str(e)}")
        return analysis

def generate_analysis(text):
    """Generate analysis for each stage and stream the results in order"""
    try:
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ...")
        logger.info(f"ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„: {text[:100]}...")
        
        logger.info("âš™ï¸ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini...")
        model = genai.GenerativeModel('models/gemini-2.0-flash-001')
        
        total_stages = len(STAGES)
        for index, stage in enumerate(STAGES, 1):
            try:
                logger.info(f"\nğŸ“Š Ø§Ù„Ù…Ø±Ø­Ù„Ø© {index}/{total_stages}: {stage}")
                logger.info("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø­Ù„Ø©...")
                
                prompt = get_stage_prompt(stage, text)
                logger.debug(f"Prompt for {stage}: {prompt[:200]}...")
                
                # Get initial analysis with timeout
                try:
                    response = model.generate_content(prompt)
                    if response and response.text:
                        initial_analysis = response.text
                        logger.info(f"âœ… ØªÙ… Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù€ {stage}")
                        
                        # Verify and enhance the analysis with timeout
                        try:
                            enhanced_analysis = verify_and_enhance_analysis(model, stage, initial_analysis, text)
                            
                            result = {
                                'stage': stage,
                                'description': STAGES_DETAILS[stage]['description'],
                                'key_points': STAGES_DETAILS[stage]['key_points'],
                                'analysis': enhanced_analysis,
                                'status': 'completed'
                            }
                        except Exception as e:
                            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù„ÙŠÙ„ {stage}: {str(e)}")
                            result = {
                                'stage': stage,
                                'description': STAGES_DETAILS[stage]['description'],
                                'key_points': STAGES_DETAILS[stage]['key_points'],
                                'analysis': initial_analysis,
                                'status': 'completed'
                            }
                    else:
                        logger.warning(f"âš ï¸ Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ù…Ø±Ø­Ù„Ø©: {stage}")
                        result = {
                            'stage': stage,
                            'description': STAGES_DETAILS[stage]['description'],
                            'key_points': STAGES_DETAILS[stage]['key_points'],
                            'analysis': "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©",
                            'status': 'error'
                        }
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© {stage}: {str(e)}")
                    result = {
                        'stage': stage,
                        'description': STAGES_DETAILS[stage]['description'],
                        'key_points': STAGES_DETAILS[stage]['key_points'],
                        'analysis': f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©: {str(e)}",
                        'status': 'error'
                    }
                
                # Stream the result for this stage
                yield f"data: {json.dumps(result, ensure_ascii=False)}\n\n"
                
                # Add a small delay between stages to prevent overload
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±Ø­Ù„Ø© {stage}: {str(e)}")
                error_result = {
                    'stage': stage,
                    'description': STAGES_DETAILS[stage]['description'],
                    'key_points': STAGES_DETAILS[stage]['key_points'],
                    'analysis': f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©: {str(e)}",
                    'status': 'error'
                }
                yield f"data: {json.dumps(error_result, ensure_ascii=False)}\n\n"
                continue
            
        logger.info("\nâœ¨ ØªÙ… Ø§ÙƒØªÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
            
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ generate_analysis: {str(e)}")
        logger.error(f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {traceback.format_exc()}")
        error_result = {
            'error': str(e),
            'status': 'error'
        }
        yield f"data: {json.dumps(error_result, ensure_ascii=False)}\n\n"

@app.route('/')
def index():
    logger.info("ğŸ“„ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
    return render_template('index.html', stages=STAGES_DETAILS)

@app.route('/analyze', methods=['GET', 'POST'])
def analyze():
    if request.method == 'GET':
        text = request.args.get('text', '')
    else:
        text = request.json.get('text', '')
    
    if not text:
        logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„")
        return jsonify({'error': 'No text provided'}), 400
    
    logger.info("ğŸ”„ Ø¨Ø¯Ø¡ Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯")
    return Response(generate_analysis(text), mimetype='text/event-stream')

if __name__ == '__main__':
    logger.info("ğŸŒ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ ØªØ·Ø¨ÙŠÙ‚ Flask...")
    app.run(debug=True) 